View(cpi)
library("writexl")
write.xlsx(cpi,"cpi.xlsx")
library("xlsx")
write.xlsx(cpi,"cpi.xlsx")
library("openxlsx")
write.xlsx(cpi,"cpi.xlsx")
fed <- read.csv("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/FEDFUNDS.xls")
fed <- read_excel("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/FEDFUNDS.xls")
View(fed)
my_keep <- list()
for(i in 1:824){
if i%3 == 0{
my_keep <- list()
for(i in 1:824){
if (i%3 == 0){
for(i in 1:824){
if (i%%3 == 0){
my_keep = append(my_keep,i)
}
}
View(my_keep)
my_keep
822 in my_keep
library(purrr)
flatten(my_keep)
library(purrr)
my_keep = flatten(my_keep)
View(my_keep)
i %in% my_keep
9 %in% my_keep
fed[my_keep:]
seq(1, 10, 2)
seq(3, 10, 2)
seq(3, 24, 3)
c(seq(3, 24, 3))
fed[c(seq(3, 24, 3)):]
fed[c(seq(3, 24, 3)),]
fed = fed[c(seq(3, 824, 3)),]
write.xlsx(fed,"my_fed.xlsx")
fed <- read.csv("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/applerevenue.csv")
fed <- read.csv("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/applerevenue.csv")
View(fed)
fed <- read.csv("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/macro_quarterly.csv")
fed <- read.csv("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/macro_monthly.csv")
fed <- fed[c(seq(4,490,3)):]
fed <- fed[c(seq(4,490,3)),]
write.xlsx(fed,"my_fed.xlsx")
View(France)
rm(France)
rm(list = ls())
data <- read_excel("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/net_i.xlsx")
View(data)
library("tree")
library("ISLR")
data <- data[,2:ncol(data)]
# Scale data
data <- as.data.frame(scale(data))
nrow(data)/3
nrow(data)/2
net_i.test <- data$net_Income_apple[-train]
set.seed(1)
data.train <- sample(1:nrow(data), nrow(data)/2)
data.test <- data[-train, ]
set.seed(1)
train <- sample(1:nrow(data), nrow(data)/2)
data.test <- data[-train, ]
net_i.test <- data$net_Income_apple[-train]
data$net_i_improve <- NA
for(i in 2:nrow(data)){
if(data['net_Income_apple',i] > data['net_Income_apple',i-1]){
data['net_i_improve',i] <- 1
}else{
data['net_i_improve',i] <- 0
}
}
data$net_i_improve <- NA
for(i in 2:nrow(data)){
if(data['net_Income_apple',i] > data['net_Income_apple',i-1] == TRUE){
data['net_Income_apple',5]
data['net_Income_apple',6]
data[5,'net_Income_apple']
data$net_i_improve <- NA
for(i in 2:nrow(data)){
if(data[i,'net_Income_apple'] > data[i-1,'net_Income_apple']){
data['net_i_improve',i] <- 1
}else{
data['net_i_improve',i] <- 0
}
}
View(data)
data <- read_excel("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/net_i.xlsx")
data <- data[,2:ncol(data)]
data <- as.data.frame(scale(data))
data$net_i_improve <- NA
for(i in 2:nrow(data)){
if(data[i,'net_Income_apple'] > data[i-1,'net_Income_apple']){
data[i,'net_i_improve'] <- 1
}else{
data[i,'net_i_improve',i] <- 0
}
}
data <- read_excel("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/net_i.xlsx")
data <- data[,2:ncol(data)]
data <- as.data.frame(scale(data))
data$net_i_improve <- NA
for(i in 2:nrow(data)){
if(data[i,'net_Income_apple'] > data[i-1,'net_Income_apple']){
data[i,'net_i_improve'] <- 1
}else{
data[i,'net_i_improve'] <- 0
}
}
View(data)
data <- data[2:nrow(data),]
set.seed(1)
train <- sample(1:nrow(data), nrow(data)/2)
data.test <- data[-train, ]
net_i.test <- data$net_i_improve[-train]
View(data)
# Make decision tree
tree.income <- tree(formula = net_i_improve ~. -net_Income_apple, data = data, subset = train)
View(tree.income)
plot(tree.income)
text(tree.income, pretty = 0, cex = .5)
data <- read_excel("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/net_i.xlsx")
data <- data[,2:ncol(data)]
data <- as.data.frame(scale(data))
data$net_i_improve <- NA
for(i in 2:nrow(data)){
if(data[i,'net_Income_apple'] > data[i-1,'net_Income_apple']){
data[i,'net_i_improve'] <- T
}else{
data[i,'net_i_improve'] <- F
}
}
data <- data[2:nrow(data),]
set.seed(1)
train <- sample(1:nrow(data), nrow(data)/2)
data.test <- data[-train, ]
net_i.test <- data$net_i_improve[-train]
tree.income <- tree(formula = net_i_improve ~. -net_Income_apple, data = data, subset = train)
plot(tree.income)
text(tree.income, pretty = 0, cex = .5)
View(data.test)
View(data.test)
tree.pred <- predict(tree.income, data.test, type="class")
View(tree.income)
# Predict on test set
tree.pred <- predict(tree.income, data.test)
table(tree.pred, net_i.test)
tree.pred <- predict(tree.income, data.test, type = "class")
# Make decision tree
tree.income <- tree(formula = as.factor(net_i_improve) ~. -net_Income_apple,
data = data, subset = train)
plot(tree.income)
text(tree.income, pretty = 0, cex = .5)
tree.pred <- predict(tree.income, data.test, type = "class")
table(tree.pred, net_i.test)
# Prediction accuracy
pred_acc = 11/(7+9+5+4)
pred_acc
print(paste("Prediction accuracy: ",pred_acc))
print(paste("Prediction accuracy: ",(pred_acc*100),"%",sep = "")
print(paste("Prediction accuracy: ",(pred_acc*100),"%"),sep = "")
print(paste("Prediction accuracy: ",(pred_acc*100),"%"),sep = "")
print(paste("Prediction accuracy: ",(pred_acc*100),"%"),sep = "")
print(paste("Prediction accuracy: ",(pred_acc*100),"%",sep = ""))
names(cv.data)
set.seed(3)
cv.data <- cv.tree(tree.income, FUN = prune.misclass)
names(cv.data)
par(mfrow = c(1, 2))
plot(cv.data$size, cv.data$dev,type = "b")
plot(cv.data$k, cv.datas$dev,type = "b")
par(mfrow = c(1, 2))
plot(cv.data$size, cv.data$dev,type = "b")
plot(cv.data$k, cv.data$dev,type = "b")
prune.data <- prune.misclass(tree.income, best = 2)
plot(prune.data)
text(prune.data, pretty = 0, cex = 0.5)
prune.data <- prune.misclass(tree.income, best = 3)
plot(prune.data)
text(prune.data, pretty = 0, cex = 0.5)
prune.data <- prune.misclass(tree.income, best = 2)
plot(prune.data)
text(prune.data, pretty = 0, cex = 0.5)
table(tree.pred, data.test)
table(tree.pred, net_i..test)
tree.pred <- predict(prune.data,data.test,type = "class")
table(tree.pred, net_i.test)
prune.data <- prune.misclass(tree.income, best = 3)
plot(prune.data)
text(prune.data, pretty = 0, cex = 0.5)
tree.pred <- predict(prune.data,data.test,type = "class")
table(tree.pred, net_i.test)
prune.data <- prune.misclass(tree.income, best = 4)
plot(prune.data)
text(prune.data, pretty = 0, cex = 0.5)
tree.pred <- predict(prune.data,data.test,type = "class")
table(tree.pred, net_i.test)
print(paste("Prediction accuracy: ",(pred_acc*100),"%",sep = ""))
library('MASS')
library('gbm')
boost.data <- gbm(formula = as.factor(net_i_improve) ~. -net_Income_apple,
data = data, distribution = "gaussian",n.trees = 5000, interaction.depth = 3)
summary(boost.data)
library("openxlsx")
library("dplyr")
library("stringr")
library("tidyr")
library("lubridate")
library("readxl")
library("ggplot2")
library("tree")
library("randomForest")
library("gbm")
library("tree")
library("ISLR")
library('MASS')
library('gbm')
# Load ackages
if(TRUE){
library("openxlsx")
library("dplyr")
library("stringr")
library("tidyr")
library("lubridate")
library("readxl")
library("ggplot2")
library("tree")
library("randomForest")
library("gbm")
library("tree")
library("ISLR")
library('MASS')
library('gbm')
}
# Import data set
data <- read_excel("/Users/frankbaring/Documents/Machine_Learning_CBS/paper/net_i.xlsx")
data <- data[,2:ncol(data)]
# Scale data
data <- as.data.frame(scale(data))
data$net_i_improve <- NA
for(i in 2:nrow(data)){
if(data[i,'net_Income_apple'] > data[i-1,'net_Income_apple']){
data[i,'net_i_improve'] <- T
}else{
data[i,'net_i_improve'] <- F
}
}
data <- data[2:nrow(data),]
# Prepare data sets
set.seed(1)
train <- sample(1:nrow(data), nrow(data)/2)
data.test <- data[-train, ]
net_i.test <- data$net_i_improve[-train]
# Make decision tree
tree.income <- tree(formula = as.factor(net_i_improve) ~. -net_Income_apple,
data = data, subset = train)
plot(tree.income)
text(tree.income, pretty = 0, cex = .5)
# Predict on test set
tree.pred <- predict(tree.income, data.test, type = "class")
table(tree.pred, net_i.test)
# Prediction accuracy
pred_acc = 11/(7+9+5+4)
print(paste("Prediction accuracy: ",(pred_acc*100),"%",sep = ""))
set.seed(3)
cv.data <- cv.tree(tree.income, FUN = prune.misclass)
names(cv.data)
par(mfrow = c(1, 2))
plot(cv.data$size, cv.data$dev,type = "b")
plot(cv.data$k, cv.data$dev,type = "b")
# Prune tree to optimal size 3
prune.data <- prune.misclass(tree.income, best = 3)
plot(prune.data)
text(prune.data, pretty = 0, cex = 0.5)
# Re-predict
tree.pred <- predict(prune.data,data.test,type = "class")
table(tree.pred, net_i.test)
# Prediction accuracy
pred_acc = 11/(7+9+5+4)
print(paste("Prediction accuracy: ",(pred_acc*100),"%",sep = ""))
boost.data <- gbm(formula = as.factor(net_i_improve) ~. -net_Income_apple,
data = data, distribution = "gaussian",n.trees = 5000, interaction.depth = 3)
summary(boost.data)
GooglePoll <- readRDS("~/Documents/Bayesian_statistics/GR5065_2023/Week09/GooglePoll.rds")
View(GooglePoll)
vetoes <- readr::read_csv("vetoes.csv", show_col_types = FALSE)
setwd("/Users/frankbaring/documents/Bayesian_Statistics/GR5065_2023/Assignments/HW3/")
vetoes <- readr::read_csv("vetoes.csv", show_col_types = FALSE)
View(vetoes)
vetoes['Term','House']
vetoes[c('Term','House')]
vetoes[c('House','Senate','Total','Regular','Pocket')]
sapply(vetoes[c('House','Senate','Total','Regular','Pocket')], sd)
type(vetoes['House'])
typeof(vetoes['House'])
sd(vetoes['House'])
sapply(vetoes[c('House','Senate','Total','Regular','Pocket')], sd)
class(vetoes$House) = "Numeric"
sapply(vetoes[c('House','Senate','Total','Regular','Pocket')], sd)
class(vetoes$Senate) = "Numeric"
class(vetoes$Senate) = "Double"
sapply(vetoes[c('House','Senate','Total','Regular','Pocket')], sd)
sd(vetoes$House)
sd(vetoes$House, na.rm = T)
sapply(vetoes[c('House','Senate','Total','Regular','Pocket')], sd(na.rm = T))
s = list()
for(i in 3:7){
append(s,sd(vetoes[,i],na.rm = T))
}
sd(vetoes[,3],na.rm = T)
sd(vetoes['House'],na.rm = T)
vetoes[3,4]
vetoes[,3]
sd(vetoes[,3])
sd(vetoes[,3],na.rm = T)
sd(vetoes[[3]],na.rm = T)
s = list()
for(i in 3:7){
append(s,sd(vetoes[[i]],na.rm = T))
}
draws <-
tibble(beta_1 = rnorm(R, m[1], s[1]),
beta_2 = rnorm(R, m[2], s[2]),
beta_3 = rnorm(R, m[3], s[3]),
beta_4 = rnorm(R, m[4], s[4]),
beta_5 = rnorm(R, m[5], s[5]))
# 1.
library(dplyr)
draws <-
tibble(beta_1 = rnorm(R, m[1], s[1]),
beta_2 = rnorm(R, m[2], s[2]),
beta_3 = rnorm(R, m[3], s[3]),
beta_4 = rnorm(R, m[4], s[4]),
beta_5 = rnorm(R, m[5], s[5]))
# 1.
library(dplyr)
R <- 10000
#drawssample_n(df, R)
# means
m = colMeans(vetoes[c('House','Senate','Total','Regular','Pocket')])
# standard dev
s = list()
for(i in 3:7){
append(s,sd(vetoes[[i]],na.rm = T))
}
draws <-
tibble(beta_1 = rnorm(R, m[1], s[1]),
beta_2 = rnorm(R, m[2], s[2]),
beta_3 = rnorm(R, m[3], s[3]),
beta_4 = rnorm(R, m[4], s[4]),
beta_5 = rnorm(R, m[5], s[5]))
library(dplyr)
R <- 10000
#drawssample_n(df, R)
# means
m = colMeans(vetoes[c('House','Senate','Total','Regular','Pocket')])
# standard dev
s = list()
for(i in 3:7){
append(s,sd(vetoes[[i]],na.rm = T))
}
m[1]
s[1]
#drawssample_n(df, R)
# means
m = colMeans(vetoes[c('House','Senate','Total','Regular','Pocket')])
m[2]
m[2]
colMeans(vetoes[c('House','Senate','Total','Regular','Pocket')])
library(dplyr)
R <- 10000
#drawssample_n(df, R)
# means
#m = colMeans(vetoes[c('House','Senate','Total','Regular','Pocket')])
# standard dev
s = list()
m = list()
for(i in 3:7){
append(s,sd(vetoes[[i]],na.rm = T))
append(m,mean(vetoes[[i]],na.rm = T))
}
draws <-
tibble(beta_1 = rnorm(R, m[1], s[1]),
beta_2 = rnorm(R, m[2], s[2]),
beta_3 = rnorm(R, m[3], s[3]),
beta_4 = rnorm(R, m[4], s[4]),
beta_5 = rnorm(R, m[5], s[5]))
s = list()
m = list()
for(i in 3:7){
append(s,sd(vetoes[[i]],na.rm = T))
append(m,mean(vetoes[[i]],na.rm = T))
}
m
m
append(m,4)
m
```{r}
library(dplyr)
R <- 10000
#drawssample_n(df, R)
# means
#m = colMeans(vetoes[c('House','Senate','Total','Regular','Pocket')])
# standard dev
s = list()
m = list()
for(i in 3:7){
s <- append(s,sd(vetoes[[i]],na.rm = T))
m <- append(m,mean(vetoes[[i]],na.rm = T))
}
draws <-
tibble(beta_1 = rnorm(R, m[1], s[1]),
beta_2 = rnorm(R, m[2], s[2]),
beta_3 = rnorm(R, m[3], s[3]),
beta_4 = rnorm(R, m[4], s[4]),
beta_5 = rnorm(R, m[5], s[5]))
m <- append(m,mean(vetoes[[3]],na.rm = T))
m
m[1]
m[2]
m[3]
m[4]
s[4]
s[1]
m[1][1]
m[[1]]
library(dplyr)
R <- 10000
#drawssample_n(df, R)
# means
#m = colMeans(vetoes[c('House','Senate','Total','Regular','Pocket')])
# standard dev
s = list()
m = list()
for(i in 3:7){
s <- append(s,sd(vetoes[[i]],na.rm = T))
m <- append(m,mean(vetoes[[i]],na.rm = T))
}
draws <-
tibble(beta_1 = rnorm(R, m[[1]], s[[1]]),
beta_2 = rnorm(R, m[[2]], s[[2]]),
beta_3 = rnorm(R, m[[3]], s[[3]]),
beta_4 = rnorm(R, m[[4]], s[[4]]),
beta_5 = rnorm(R, m[[5]], s[[5]]))
draws
head(draws)
library(dplyr)
R <- 10000
#drawssample_n(df, R)
# means
#m = colMeans(vetoes[c('House','Senate','Total','Regular','Pocket')])
# standard dev
s = list()
m = list()
for(i in 3:8){
s <- append(s,sd(vetoes[[i]],na.rm = T))
m <- append(m,mean(vetoes[[i]],na.rm = T))
}
draws <-
tibble(beta_1 = rnorm(R, m[[1]], s[[1]]),
beta_2 = rnorm(R, m[[2]], s[[2]]),
beta_3 = rnorm(R, m[[3]], s[[3]]),
beta_4 = rnorm(R, m[[4]], s[[4]]),
beta_5 = rnorm(R, m[[5]], s[[5]]),
beta_6 = rnorm(R, m[[6]], s[[6]]))
head(draws)
# 2.
X <- model.matrix(beta_6 ~ beta_1 + beta_2 + beta_3 + beta_4 + beta_5, data = draws)
x_bar <- colMeans(X)
X <- sweep(X, MARGIN = 2, STATS = x_bar, FUN = `-`) # subtract average from each column
colnames(X) # formula expands to 16 dummy variables
if(TRUE){#Load packages
library("dplyr")
library("stringr")
library("tidyr")
library("tidyverse")
library("lubridate")
library("ggplot2")
library("keras")
library("magrittr")
library("neuralnet")
}#Load packages
#Rounding function
round.off <- function (x, digits=0)
{
posneg = sign(x)
z = trunc(abs(x) * 10 ^ (digits + 1)) / 10
z = floor(z * posneg + 0.5) / 10 ^ digits
return(z)
}
#Load Data
data <- read_csv("Advertising.csv")
root <- "/Users/frankbaring/documents/Machine_Learning_CBS/Homeworks/Answers/HW3/data/"
setwd(root)
data <- read_csv("Advertising.csv")
data <- data[,-1]
#Split Data
set.seed(1)
val <- data[sample(nrow(data), 25), ] #Validation set
val_x <- subset(val,select = -sales)
val_y <- subset(val,select = sales)
train <- data[-sample(nrow(data), 25), ] #Train set
train_x <- subset(train,select = -sales)
train_y <- subset(train,select = sales)
#Fit Network
network <- keras_model_sequential() %>%
layer_dense(units = round.off(175/2,0), activation = "relu") %>% #50 hidden units
layer_dense(units = 1, activation = "softmax")
